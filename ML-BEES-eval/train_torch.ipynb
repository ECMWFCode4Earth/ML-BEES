{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5442df6-b477-42de-81a6-c523fa8f9084",
   "metadata": {
    "tags": []
   },
   "source": [
    "import xarray as xr\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import tensor\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "import zarr\n",
    "import pandas as pd\n",
    "import cftime\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "\n",
    "def r2_score_multi(y_pred: np.ndarray, y_true: np.ndarray) -> float:\n",
    "    \"\"\"Calculated the r-squared score between 2 arrays of values\n",
    "\n",
    "    :param y_pred: predicted array\n",
    "    :param y_true: \"truth\" array\n",
    "    :return: r-squared metric\n",
    "    \"\"\"\n",
    "    return r2_score(y_pred.flatten(), y_true.flatten())\n",
    "\n",
    "\n",
    "with open(f\"../config.yaml\") as stream:\n",
    "    try:\n",
    "        CONFIG = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "# Set rollout length\n",
    "ROLLOUT=4  # 12\n",
    "torch.cuda.empty_cache()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d64b979",
   "metadata": {},
   "source": [
    "CONFIG"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cbe8f02-b212-456e-89b9-c8e164dfd142",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Set device\n",
    "if torch.cuda.is_available(): \n",
    "    dev = \"cuda:0\" \n",
    "else: \n",
    "    dev = \"cpu\" \n",
    "device = torch.device(dev) \n",
    "device"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27842b50-0db4-4c36-980f-39d75deeb6ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Inspect dataset and variables\n",
    "da = xr.open_zarr(\"/data/ecland_i6aj_o400_2010_2022_6h_euro.zarr\")\n",
    "da"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac16e01",
   "metadata": {},
   "source": [
    "class EcDataset(Dataset):\n",
    "    # load the dataset\n",
    "    def __init__(\n",
    "        self,\n",
    "        start_yr=2015,\n",
    "        end_yr=2020,\n",
    "        x_idxs=(0, \"None\"),\n",
    "        path=\"/data/ecland_i6aj_o400_2010_2022_6h_euro.zarr\",\n",
    "        roll_out=ROLLOUT,\n",
    "    ):\n",
    "        self.ds_ecland = zarr.open(path)\n",
    "        # Create time index to select appropriate data range\n",
    "        date_times = pd.to_datetime(\n",
    "            cftime.num2pydate(\n",
    "                self.ds_ecland[\"time\"], self.ds_ecland[\"time\"].attrs[\"units\"]\n",
    "            )\n",
    "        )\n",
    "        self.start_index = min(np.argwhere(date_times.year == int(start_yr)))[0]\n",
    "        self.end_index = max(np.argwhere(date_times.year == int(end_yr)))[0]\n",
    "        self.times = np.array(date_times[self.start_index : self.end_index])\n",
    "        self.len_dataset = self.end_index - self.start_index\n",
    "\n",
    "        # Select points in space\n",
    "        self.x_idxs = (0, None) if \"None\" in x_idxs else x_idxs\n",
    "        self.x_size = len(self.ds_ecland[\"x\"][slice(*self.x_idxs)])\n",
    "        self.lats = self.ds_ecland[\"lat\"][slice(*self.x_idxs)]\n",
    "        self.lons = self.ds_ecland[\"lon\"][slice(*self.x_idxs)]\n",
    "\n",
    "        # List of climatological time-invariant features\n",
    "        self.static_feat_lst = CONFIG[\"clim_feats\"]\n",
    "        self.clim_index = [\n",
    "            list(self.ds_ecland[\"clim_variable\"]).index(x) for x in CONFIG[\"clim_feats\"]\n",
    "        ]\n",
    "        # List of features that change in time\n",
    "        self.dynamic_feat_lst = CONFIG[\"dynamic_feats\"]\n",
    "        self.dynamic_index = [\n",
    "            list(self.ds_ecland[\"variable\"]).index(x) for x in CONFIG[\"dynamic_feats\"]\n",
    "        ]\n",
    "        # Prognostic target list\n",
    "        self.targ_lst = CONFIG[\"targets_prog\"]\n",
    "        self.targ_index = [\n",
    "            list(self.ds_ecland[\"variable\"]).index(x) for x in CONFIG[\"targets_prog\"]\n",
    "        ]\n",
    "        # Diagnostic target list\n",
    "        self.targ_diag_lst = CONFIG[\"targets_diag\"]\n",
    "        self.targ_diag_index = [\n",
    "            list(self.ds_ecland[\"variable\"]).index(x) for x in CONFIG[\"targets_diag\"]\n",
    "        ]\n",
    "\n",
    "        # Define the statistics used for normalising the data\n",
    "        self.x_dynamic_means = tensor(self.ds_ecland.data_means[self.dynamic_index])\n",
    "        self.x_dynamic_stdevs = tensor(self.ds_ecland.data_stdevs[self.dynamic_index])\n",
    "\n",
    "        # Create time-invariant static climatological features\n",
    "        x_static = tensor(\n",
    "            self.ds_ecland.clim_data[slice(*self.x_idxs), self.clim_index]\n",
    "        )\n",
    "        clim_means = tensor(self.ds_ecland.clim_means[self.clim_index])\n",
    "        clim_stdevs = tensor(self.ds_ecland.clim_stdevs[self.clim_index])\n",
    "        self.x_static_scaled = self.transform(\n",
    "            x_static, clim_means, clim_stdevs\n",
    "        ).reshape(1, self.x_size, -1)\n",
    "\n",
    "        # Define statistics for normalising the targets\n",
    "        self.y_prog_means = tensor(self.ds_ecland.data_means[self.targ_index])\n",
    "        self.y_prog_stdevs = tensor(self.ds_ecland.data_stdevs[self.targ_index])\n",
    "\n",
    "        self.y_diag_means = tensor(self.ds_ecland.data_means[self.targ_diag_index])\n",
    "        self.y_diag_stdevs = tensor(self.ds_ecland.data_stdevs[self.targ_diag_index])\n",
    "\n",
    "        self.rollout = roll_out\n",
    "\n",
    "    def transform(self, x: np.ndarray, mean: np.ndarray, std: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Transform data with mean and stdev.\n",
    "\n",
    "        :param x: data :param mean: mean :param std: standard deviation :return:\n",
    "        normalised data\n",
    "        \"\"\"\n",
    "        x_norm = (x - mean) / (std + 1e-5)\n",
    "        return x_norm\n",
    "\n",
    "    def inv_transform(\n",
    "        self, x_norm: np.ndarray, mean: np.ndarray, std: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Inverse transform on data with mean and stdev.\n",
    "\n",
    "        :param x_norm: normlised data :param mean: mean :param std: standard deviation\n",
    "        :return: unnormalised data\n",
    "        \"\"\"\n",
    "        x = (x_norm * (std + 1e-5)) + mean\n",
    "        return x\n",
    "\n",
    "    def load_data(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:\n",
    "        \"\"\"Load data into memory. **CAUTION ONLY USE WHEN WORKING WITH DATASET THAT FITS\n",
    "        IN MEM**\n",
    "\n",
    "        :return: static_features, dynamic_features, prognostic_targets,\n",
    "        diagnostic_targets\n",
    "        \"\"\"\n",
    "        ds_slice = tensor(\n",
    "            self.ds_ecland.data[\n",
    "                self.start_index : self.end_index, slice(*self.x_idxs), :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        X = ds_slice[:, :, self.dynamic_index]\n",
    "        X = self.transform(X, self.x_dynamic_means, self.x_dynamic_stdevs)\n",
    "\n",
    "        X_static = self.x_static_scaled\n",
    "\n",
    "        Y_prog = ds_slice[:, :, self.targ_index]\n",
    "        Y_prog = self.transform(Y_prog, self.y_prog_means, self.y_prog_stdevs)\n",
    "\n",
    "        Y_diag = ds_slice[:, :, self.targ_diag_index]\n",
    "        Y_diag = self.transform(Y_diag, self.y_diag_means, self.y_diag_stdevs)\n",
    "        return X_static, X, Y_prog, Y_diag\n",
    "\n",
    "    # number of rows in the dataset\n",
    "    def __len__(self):\n",
    "        return self.len_dataset - 1 - self.rollout\n",
    "\n",
    "    # get a row at an index\n",
    "    def __getitem__(self, idx):\n",
    "        idx = idx + self.start_index\n",
    "        ds_slice = tensor(\n",
    "            self.ds_ecland.data[\n",
    "                slice(idx, idx + self.rollout + 1), slice(*self.x_idxs), :\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        X = ds_slice[:, :, self.dynamic_index]\n",
    "        X = self.transform(X, self.x_dynamic_means, self.x_dynamic_stdevs)\n",
    "\n",
    "        X_static = self.x_static_scaled.expand(self.rollout, -1, -1)\n",
    "\n",
    "        Y_prog = ds_slice[:, :, self.targ_index]\n",
    "        Y_prog = self.transform(Y_prog, self.y_prog_means, self.y_prog_stdevs)\n",
    "\n",
    "        Y_diag = ds_slice[:, :, self.targ_diag_index]\n",
    "        Y_diag = self.transform(Y_diag, self.y_diag_means, self.y_diag_stdevs)\n",
    "\n",
    "        Y_inc = Y_prog[1:, :, :] - Y_prog[:-1, :, :]\n",
    "        return X_static, X[:-1], Y_prog[:-1], Y_inc, Y_diag[:-1]\n",
    "    \n",
    "    # get indexes for train and test rows\n",
    "    def get_splits(self, n_test=0.2):\n",
    "        # determine sizes\n",
    "        generator = torch.Generator().manual_seed(42)\n",
    "        test_size = round(n_test * (self.len_dataset-1-self.rollout)) \n",
    "        train_size = (self.len_dataset-1-self.rollout) - test_size\n",
    "        # calculate the split\n",
    "        return random_split(self, [train_size, test_size], generator=generator)\n",
    "\n",
    "\n",
    "class NonLinRegDataModule(pl.LightningDataModule):\n",
    "    \"\"\"Pytorch lightning specific data class.\"\"\"\n",
    "    def setup(self, stage):\n",
    "        generator = torch.Generator().manual_seed(42)\n",
    "        training_data = EcDataset()\n",
    "        self.train, self.test = training_data.get_splits()\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=50, shuffle=True, num_workers=8)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=50, shuffle=False, num_workers=8)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96c2b1e3",
   "metadata": {},
   "source": [
    "# Define a neural network model with hidden layers and activation functions\n",
    "class NonLinearRegression(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size_clim,\n",
    "        input_size_met,\n",
    "        input_size_state,\n",
    "        hidden_size,\n",
    "        output_size,\n",
    "        mu_norm=0,\n",
    "        std_norm=1,\n",
    "        dataset=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Normalization vector for delta_x's\n",
    "        self.mu_norm = tensor(mu_norm)\n",
    "        self.std_norm = tensor(std_norm)\n",
    "        self.ds = dataset\n",
    "\n",
    "        # Define layers\n",
    "        input_dim = input_size_clim + input_size_met + input_size_state\n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(0.15)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.fc4 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, clim_feats, met_feats, state_feats):\n",
    "        combined = torch.cat((clim_feats, met_feats, state_feats), dim=-1)\n",
    "        x = self.relu1(self.fc1(combined))\n",
    "        x = self.dropout(self.relu2(self.fc2(x)))\n",
    "        x = self.relu3(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "    def transform(self, x, mean, std):\n",
    "        x_norm = (x - mean) / (std + 1e-5)\n",
    "        # x_norm = (x - mean) / (std)\n",
    "        return x_norm\n",
    "\n",
    "    def predict_step(\n",
    "        self, clim_feats, met_feats, states, diagnostics\n",
    "    ) -> Tuple[tensor, tensor]:\n",
    "        \"\"\"Given arrays of features produces a prediction for all timesteps.\n",
    "\n",
    "        :return: (prognost_targets, diagnostic_targets)\n",
    "        \"\"\"\n",
    "        preds = states.clone().to(self.device)\n",
    "        len_run = preds.shape[0]\n",
    "\n",
    "        for x in range(len_run):\n",
    "            preds_dx = self.forward(\n",
    "                clim_feats, met_feats[[x]], preds[[x]]\n",
    "            )\n",
    "            if x < (len_run - 1):\n",
    "                preds[x + 1] = preds[x] + preds_dx\n",
    "        return preds\n",
    "\n",
    "    def MSE_loss(self, logits, labels):\n",
    "        # criterion = nn.MSELoss()\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        return criterion(logits, labels)\n",
    "\n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        x_clim, x_met, x_state, y, _ = train_batch\n",
    "        logits = self.forward(x_clim, x_met, x_state)\n",
    "        mean = self.mu_norm.to(self.device)\n",
    "        std = self.std_norm.to(self.device)\n",
    "        loss = self.MSE_loss(\n",
    "            self.transform(logits, mean, std), self.transform(y, mean, std)\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "        )\n",
    "\n",
    "        if ROLLOUT > 1:\n",
    "            x_state_rollout = x_state.clone()\n",
    "            y_rollout = y.clone()\n",
    "            for step in range(ROLLOUT):\n",
    "                # x = [batch_size=8, lookback (7) + rollout (3) = 10, n_feature = 37]\n",
    "                x0 = x_state_rollout[:, step, :, :].clone()  # select input with lookback.\n",
    "                y_hat = self.forward(\n",
    "                    x_clim[:, step, :, :], x_met[:, step, :, :], x0\n",
    "                )  # prediction at rollout step\n",
    "                if step < ROLLOUT - 1:\n",
    "                    x_state_rollout[:, step + 1, :, :] = (\n",
    "                        x_state_rollout[:, step, :, :].clone() + y_hat\n",
    "                    )  # overwrite x with prediction.\n",
    "                y_rollout[:, step, :, :] = y_hat  # overwrite y with prediction.\n",
    "            step_loss = self.MSE_loss(\n",
    "                self.transform(y_rollout, mean, std), self.transform(y, mean, std)\n",
    "            )\n",
    "            # step_loss = step_loss / ROLLOUT\n",
    "            self.log(\n",
    "                \"step_loss\",\n",
    "                step_loss,\n",
    "            )\n",
    "\n",
    "            loss += step_loss\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        x_clim, x_met, x_state, y, _ = val_batch\n",
    "        mean = self.mu_norm.to(self.device)\n",
    "        std = self.std_norm.to(self.device)\n",
    "        logits = self.forward(x_clim, x_met, x_state)\n",
    "        loss = self.MSE_loss(\n",
    "            self.transform(logits, mean, std), self.transform(y, mean, std)\n",
    "        )\n",
    "        r2 = r2_score_multi(\n",
    "            self.transform(logits, mean, std).cpu(),\n",
    "            self.transform(y, mean, std).cpu(),\n",
    "        )\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, sync_dist=True)\n",
    "        self.log(\"val_R2\", r2, on_step=False, on_epoch=True, sync_dist=True)\n",
    "\n",
    "        if ROLLOUT > 1:\n",
    "            x_state_rollout = x_state.clone()\n",
    "            y_rollout = y.clone()\n",
    "            for step in range(ROLLOUT):\n",
    "                # x = [batch_size=8, lookback (7) + rollout (3) = 10, n_feature = 37]\n",
    "                x0 = x_state_rollout[\n",
    "                    :, step, :, :\n",
    "                ].clone()  # select input with lookback.\n",
    "                y_hat = self.forward(\n",
    "                    x_clim[:, step, :, :], x_met[:, step, :, :], x0\n",
    "                )  # prediction at rollout step\n",
    "                if step < ROLLOUT - 1:\n",
    "                    x_state_rollout[:, step + 1, :, :] = (\n",
    "                        x_state_rollout[:, step, :, :].clone() + y_hat\n",
    "                    )  # overwrite x with prediction.\n",
    "                y_rollout[:, step, :, :] = y_hat  # overwrite y with prediction.\n",
    "            step_loss = self.MSE_loss(\n",
    "                self.transform(y_rollout, mean, std), self.transform(y, mean, std)\n",
    "            )\n",
    "            # step_loss = step_loss / ROLLOUT\n",
    "            self.log(\n",
    "                \"val_step_loss\",\n",
    "                step_loss,\n",
    "            )\n",
    "            loss += step_loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45add160-0f7e-4bac-8b1f-a786c21d3199",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load the dataset\n",
    "ds_example = EcDataset()\n",
    "print(ds_example.__len__())\n",
    "\n",
    "# calculate split\n",
    "train, test = ds_example.get_splits()\n",
    "\n",
    "# prepare data loaders\n",
    "train_dl = DataLoader(train, batch_size=10, shuffle=True)  # shuffle=False)\n",
    "test_dl = DataLoader(test, batch_size=10, shuffle=False)\n",
    "\n",
    "# inspect shape of a single batch, should be (batch_size, rollout_size, x_dim_size, feat/targ_size)\n",
    "_, xx, _, yy, _ = next(iter(train_dl))\n",
    "print(xx.shape)\n",
    "print(yy.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e04f99a2-e171-4597-9f40-aa852dc01a6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "std = ds_example.y_prog_stdevs.cpu().numpy()\n",
    "ds_mean = ds_example.ds_ecland.data_1stdiff_means[ds_example.targ_index] / (std + 1e-5)\n",
    "ds_std = ds_example.ds_ecland.data_1stdiff_stdevs[ds_example.targ_index] / (std + 1e-5)\n",
    "\n",
    "#df = pd.DataFrame(yy.reshape(-1, len(ds_example.targ_lst)).cpu().numpy() / (ds_std), columns=ds_example.targ_lst)\n",
    "df = pd.DataFrame(yy.reshape(-1, len(ds_example.targ_lst)).cpu().numpy(), columns=ds_example.targ_lst)\n",
    "df.hist(figsize=(12,12),)\n",
    "plt.suptitle(\"Target Variable Distributions\")\n",
    "plt.tight_layout()\n",
    "\n",
    "del ds_example, xx, yy"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d682a6e4-51b6-4f6c-aa6b-d13d7cd0fdeb",
   "metadata": {
    "tags": []
   },
   "source": [
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "data_module = NonLinRegDataModule()\n",
    "dataset = EcDataset()\n",
    "csv_logger = CSVLogger('logs', name='testing')  # Change 'logs' to the directory where you want to save the logs\n",
    "\n",
    "std = dataset.y_prog_stdevs.cpu().numpy()\n",
    "ds_mean = dataset.ds_ecland.data_1stdiff_means[dataset.targ_index] / (std + 1e-5)\n",
    "ds_std = dataset.ds_ecland.data_1stdiff_stdevs[dataset.targ_index] / (std + 1e-5)\n",
    "\n",
    "# train\n",
    "input_clim_dim = dataset.x_static_scaled.shape[-1]\n",
    "input_met_dim = len(dataset.dynamic_feat_lst)\n",
    "input_state_dim = len(dataset.targ_lst)\n",
    "output_dim = len(dataset.targ_lst)  # Number of output targets\n",
    "hidden_dim = 172  # Number of hidden units\n",
    "model_pyt = NonLinearRegression(\n",
    "    input_clim_dim,\n",
    "    input_met_dim,\n",
    "    input_state_dim,\n",
    "    hidden_dim,\n",
    "    output_dim,\n",
    "    mu_norm=ds_mean,\n",
    "    std_norm=ds_std,\n",
    "    dataset=dataset,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7d6df17-1c5e-4116-bb29-1283457f6b09",
   "metadata": {
    "tags": []
   },
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "checkpoint_callback = ModelCheckpoint(monitor=\"val_step_loss\", mode=\"min\")\n",
    "# torch.set_float32_matmul_precision('medium')\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    # precision='bf16-mixed',\n",
    "    logger=csv_logger,\n",
    "    max_epochs=50,  # 40  # 100,  # 200,\n",
    ")\n",
    "\n",
    "trainer.fit(model_pyt, data_module)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e9c55973-635c-48bd-a1c9-fd4ab2bf9d04",
   "metadata": {},
   "source": [
    "# Testing out the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be34c20c-bb69-4792-8d30-360b8b133337",
   "metadata": {
    "tags": []
   },
   "source": [
    "model_pyt.eval()\n",
    "test_ds = EcDataset(start_yr=\"2018\", \n",
    "                    end_yr=\"2022\", \n",
    "                    path=\"/perm/daep/ec_land_db_test/ecland_i6aj_2018_2022_6H.zarr\",\n",
    "                    x_idxs=(500-4, 500+4))\n",
    "feats = test_ds.ds_ecland[dataset.dynamic_feat_lst].isel(x=4, time=slice(0,-1)).compute()\n",
    "feats_arr2 = np.array(feats.to_array().values.T)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3877daf7-59f1-40c7-bfac-0a9d55849fb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "test_ds.ds_ecland.x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630414a0-9d82-4725-ae08-bd8807301719",
   "metadata": {
    "tags": []
   },
   "source": [
    "model_pyt.cpu()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11182af4-a1ef-4f0f-b896-9c9d8b0394b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "test_ds.X_static_scaled.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c311f-02b1-49d1-850b-71938c80bdf8",
   "metadata": {
    "tags": []
   },
   "source": [
    "%%time\n",
    "# Loop over all times and iteratively apply the ML model to construct a 5-year ML estimate to the ec-land model\n",
    "feats_arr3 = dataset.dynamic_feat_scalar.transform(\n",
    "    tensor(feats_arr2, dtype=torch.float32))#.reshape(1, -1, 19)  # .to(device)\n",
    "static_feats = test_ds.X_static_scaled[:,4,:]\n",
    "print(feats_arr3.shape)\n",
    "\n",
    "for x in range(len(feats_arr2)-1):\n",
    "    if x % 1000 == 0:\n",
    "        print(f\"on step {x}...\")\n",
    "    with torch.no_grad():\n",
    "        preds = model_pyt(torch.cat((static_feats, feats_arr3[[x]]), axis=-1))\n",
    "        feats_arr3[x+1, -len(dataset.targ_lst):] = feats_arr3[x, -len(dataset.targ_lst):] + preds\n",
    "        \n",
    "feats_arr3 = dataset.dynamic_feat_scalar.inv_transform(feats_arr3).cpu().numpy().reshape(-1, 19)\n",
    "feats_arr3 = np.clip(feats_arr3, 0, None)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6938d15-138e-4f06-a29a-65e0daed9dfa",
   "metadata": {
    "tags": []
   },
   "source": [
    "fig = plt.figure(figsize=(16,8))\n",
    "ax1 = plt.subplot(331)\n",
    "ax2 = plt.subplot(332)\n",
    "ax3 = plt.subplot(333)\n",
    "ax4 = plt.subplot(334)\n",
    "ax5 = plt.subplot(335)\n",
    "ax6 = plt.subplot(336)\n",
    "ax7 = plt.subplot(337)\n",
    "\n",
    "def ailand_plot(var_name, ax, ylabel, ax_title, test_date=\"2022-01-01\"):\n",
    "    \"\"\"Plotting function for the ec-land database and ai-land model output\n",
    "\n",
    "    :param var_name: parameter variable name\n",
    "    :param ax: the axes to plot on\n",
    "    :param ylabel: y-label for plot\n",
    "    :param ax_title: title for plot\n",
    "    :param test_date: date to plot vertical line (train/test split), defaults to \"2022-01-01\"\n",
    "    :return: plot axes\n",
    "    \"\"\"\n",
    "    feats[var_name].plot(label=\"ec-land\", ax=ax)\n",
    "    ax.plot(feats.time[:], feats_arr3[:, dataset.dynamic_feat_lst.index(var_name)], '--', label=\"ai-land\")\n",
    "    ax.axvline(feats.sel(time=test_date).time.values[0], color=\"k\", linestyle=\"--\")\n",
    "    ax.set_xlim(feats.time.values[[0,-1]])\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(ax_title)\n",
    "    return ax\n",
    "\n",
    "ailand_plot(\"swvl1\", ax1, \"Soil Moisture (m3 m-3)\", \"Soil Moisture Layer 1\")\n",
    "ailand_plot(\"swvl2\", ax2, \"Soil Moisture (m3 m-3)\", \"Soil Moisture Layer 2\")\n",
    "ailand_plot(\"swvl3\", ax3, \"Soil Moisture (m3 m-3)\", \"Soil Moisture Layer 3\")\n",
    "ailand_plot(\"stl1\", ax4, \"Soil Temperature (K)\", \"Soil Temperature Layer 1\")\n",
    "ailand_plot(\"stl2\", ax5, \"Soil Temperature (K)\", \"Soil Temperature Layer 2\")\n",
    "ailand_plot(\"stl3\", ax6, \"Soil Temperature (K)\", \"Soil Temperature Layer 3\")\n",
    "ailand_plot(\"snowc\", ax7, \"Snow Cover Fraction (-)\", \"Snow Cover Fraction\")\n",
    "\n",
    "plt.legend()\n",
    "fig.suptitle(f\"ec/ai-land train-test comparison ({feats.lat.values: .2f} N, {feats.lon.values: .2f} E)\")\n",
    "fig.tight_layout()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d617ecb-9e61-42d2-85f4-c2e0450b4008",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
