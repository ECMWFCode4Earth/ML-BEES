{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'/home/ch23/ML-BEES_yk/ML-BEES-eval/eval_utilities')\n",
    "\n",
    "from eval_utilities import spatial_temporal_metrics as stm\n",
    "from eval_utilities import visualization as vis\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import visualization\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(f\"config.yaml\") as stream:\n",
    "    try:\n",
    "        CONFIG = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "# load the predicted variables\n",
    "variables = CONFIG[\"targets_prog\"] + CONFIG[\"targets_diag\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all the ensemble members and collect into \n",
    "# load ensembles name in a list\n",
    "# prepare the numpy ensemble array\n",
    "import dask.array as da\n",
    "\n",
    "def find_files_with_name(directory, filename):\n",
    "    # Create a pattern for glob\n",
    "    pattern = os.path.join(directory, f'*{filename}*')\n",
    "    \n",
    "    # Use glob to find all files matching the pattern\n",
    "    matching_files = glob.glob(pattern)\n",
    "    \n",
    "    return matching_files\n",
    "\n",
    "# Example usage\n",
    "directory_path = '/data/ch23/data_ch23/unimp_ens'  # Replace with your folder path\n",
    "file_name = 'unimp'  # File name to search for\n",
    "files_list = find_files_with_name(directory_path, file_name)\n",
    "\n",
    "# preprocess .zarr to da.array\n",
    "ens_file_list=[]\n",
    "for i,ens_file in enumerate(files_list):\n",
    "\n",
    "    ens1=xr.open_zarr(ens_file)\n",
    "    desired_chunks = (4, 10051, 17)  # Adjust based on your desired chunk sizes\n",
    "    ens1 = ens1.chunk({'time': 4, 'x': 10051, 'variable': 17})\n",
    "    ens1_array=ens1.data\n",
    "    ens_file_list.append(ens1_array)\n",
    "\n",
    "stacked_ens = da.stack(ens_file_list)\n",
    "y_pred=stacked_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load groundtruth\n",
    "v1=xr.open_zarr(\"/data/ch23/data_ch23/unimp_ens/euro_unimp_1_train_2010_2019_val_2020_2020.zarr\")\n",
    "\n",
    "train_ds = xr.open_zarr(\"/data/ecland_i6aj_o400_2010_2022_6h_euro.zarr\").sel(time=slice(\"2020\", \"2022\"),variable=variables)  \n",
    "# select the same variable list as prediction\n",
    "y_true=train_ds.data # make sure y_true is dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "crps=xr.open_zarr(\"/data/ch23/evalution_results/uncertainty/crps_unimp_test_dask.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_zarr_map(zarr_eval, var, path_png, min_perc, max_perc, time_point=False):\n",
    "\n",
    "    \"\"\"\n",
    "    Visualize the original zarr file -- ecland or ai-land output;\n",
    "    select a single time point of one variable; Or plot the metrics for one variable;\n",
    "    save the figure to the path\n",
    "\n",
    "    --- Parameters ---\n",
    "    zarr_eval:   the zarr file; zarr should be xarray.Dataset\n",
    "    vars:       str or iterable of str\n",
    "    path_png:   path to save the figure; should include the metrics name if plot the metric\n",
    "    min_prec:   percentile for lower limit, by default 1%\n",
    "    max_prec:   percentile for upper limit, by default 99%\n",
    "    time_point:   bool-by daulft False or int\n",
    "\n",
    "    --- Returns ---\n",
    "    show the map and save in the path\n",
    "    \"\"\"\n",
    "    if time_point==False:\n",
    "        zarr_eval_selected = zarr_eval.sel(variable=var)\n",
    "    else:\n",
    "        zarr_eval_selected = zarr_eval.isel(time=time_point).sel(variable=var)\n",
    "\n",
    "    # Create the scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # filter the nan and inf value to calculate min/max percentile\n",
    "\n",
    "    valid_mask = ~np.isnan(zarr_eval_selected.crps.values) & ~np.isinf(zarr_eval_selected.crps.values)\n",
    "\n",
    "    # Filter the array to keep only the valid values\n",
    "    compressed_array = zarr_eval_selected.crps.values[valid_mask]\n",
    "\n",
    "    # pre-define a min and max for a quick visualization; vmin/vmax based on the 1 and 99 percentile \n",
    "    vmin=np.percentile(compressed_array, min_perc, axis=0)\n",
    "    vmax=np.percentile(compressed_array, max_perc, axis=0)\n",
    "\n",
    "    scatter = zarr_eval_selected.plot.scatter(\n",
    "        x=\"lon\", y=\"lat\", hue=\"crps\", s=10, edgecolors=\"none\", ax=ax, vmin=vmin,vmax=vmax)\n",
    "    \n",
    "    # Increase font sizes\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=16)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=16)\n",
    "    ax.set_title(ax.get_title(), fontsize=18)\n",
    "    ax.tick_params(labelsize=14)\n",
    "    if scatter.colorbar is not None:\n",
    "        scatter.colorbar.ax.tick_params(labelsize=14)\n",
    "        scatter.colorbar.set_label(\"Data\", fontsize=16)  # Set the label for the colorbar\n",
    "    \n",
    "    fig.savefig(path_png+'_%s.png' % var, bbox_inches=\"tight\") # path_png should include the metrics name\n",
    "\n",
    "    #plt.show()\n",
    "    # Close the figure to prevent it from displaying\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure_path='/data/ch23/evalution_results/uncertainty/visualization/'\n",
    "\n",
    "for var in crps.variable.values:\n",
    "    vis_zarr_map(crps, var, \n",
    "                            figure_path+'crps'\n",
    "                            ,1,99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try the dask version\n",
    "def dask_sort_along_axis(arr, axis=0):\n",
    "    \"\"\"\n",
    "    Sort a Dask array along a specified axis using a custom function.\n",
    "    \"\"\"\n",
    "    return da.map_blocks(lambda x: np.sort(x, axis=axis), arr, dtype=arr.dtype)\n",
    "\n",
    "\n",
    "def crps_dask(y_true, y_pred, time=True, sample_weight=None, norm=False):\n",
    "    \"\"\"\n",
    "    Calculate Continuous Ranked Probability Score -- CRPS is measured in the same units as the variable\n",
    "    Data based on size (time, lat*lon, vars) where N=number of samples (in time) and each grid point will have one value\n",
    "    Args:\n",
    "        y_true (np.array): Ground truth with shape (time, lat*lon, vars).\n",
    "        y_pred (np.array): Predicted values from n_seeds ensembles with shape (n_seeds, time, lat*lon, vars).\n",
    "        sample_weight (np.array, optional): Sample weights.\n",
    "        norm (bool, optional): Flag to normalize the CRPS scores.\n",
    "    \n",
    "    Returns:\n",
    "        np.array: CRPS score for each height profile (lat*lon, vars).Returns:\n",
    "        \n",
    "    modified based on@https://github.com/lm2612/WaveNet_UQ/\n",
    "    \"\"\"\n",
    "    # Number of ensemble predictions\n",
    "    num_samples = y_pred.shape[0]\n",
    "    \n",
    "    # Sort predictions along the ensemble axis\n",
    "    #y_pred = da.sort(y_pred, axis=0)\n",
    "\n",
    "    y_pred = dask_sort_along_axis(y_pred, axis=0)\n",
    "    \n",
    "    # Calculate differences between consecutive sorted predictions\n",
    "    diff = y_pred[1:] - y_pred[:-1]\n",
    "    \n",
    "    # Calculate weights for CRPS calculation\n",
    "    weight = da.arange(1, num_samples) * da.arange(num_samples - 1, 0, -1)\n",
    "    #weight = weight[:, da.newaxis, da.newaxis, da.newaxis]\n",
    "    weight = da.asarray(weight[:, None, None, None])\n",
    "    weight = weight.rechunk((weight.shape[0], 1, 1, 1))\n",
    "    \n",
    "    # Calculate the absolute error\n",
    "    y_true_expanded = y_true.expand_dims(dim=\"ensemble\", axis=0)\n",
    "\n",
    "    # Convert to Dask array if necessary\n",
    "    y_true_dask = y_true_expanded.data\n",
    "\n",
    "    #absolute_error = da.mean(da.abs(y_pred - da.expand_dims(y_true, 0)), axis=0)\n",
    "    absolute_error = da.mean(da.abs(y_pred - y_true_dask), axis=0)\n",
    "    \n",
    "    # Calculate per observation CRPS\n",
    "    per_obs_crps = absolute_error - da.sum(diff * weight, axis=0) / num_samples**2\n",
    "\n",
    "    if time==False:\n",
    "        return per_obs_crps\n",
    "\n",
    "    # Normalization if required\n",
    "    if norm:\n",
    "        crps_normalized = da.where(da.abs(y_true) > 1E-14, per_obs_crps / da.abs(y_true), da.nan)\n",
    "        return da.nanmean(crps_normalized, axis=0)\n",
    "    \n",
    "    # Return the weighted average CRPS\n",
    "    if time:\n",
    "        return da.average(per_obs_crps, axis=0, weights=sample_weight)\n",
    "crps_score_time_series = crps_dask(y_true[:,:,:17], y_pred[:,:,:,:17], time=False, sample_weight=None, norm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'crps_score_time_series' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcrps_score_time_series\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'crps_score_time_series' is not defined"
     ]
    }
   ],
   "source": [
    "crps_score_time_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a new xarray Dataset with CRPS scores\n",
    "crps_score_time_series_ds = xr.Dataset(\n",
    "    {\n",
    "        \"crps\": ((\"time\",\"x\", \"variable\"), crps_score_time_series) # 3 dim\n",
    "    },\n",
    "    coords={\n",
    "        \"time\": (\"time\", v1.time.values),\n",
    "        \"lat\": (\"x\", v1.lat.values),\n",
    "        \"lon\": (\"x\", v1.lon.values),\n",
    "        \"variable\": v1.variable.values,\n",
    "    }\n",
    ")\n",
    "# Save the new dataset as a .zarr file\n",
    "crps_score_time_series_ds.to_zarr(\"/data/ch23/evalution_results/uncertainty/crps_unimp_dask_timeseries.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the time series and uncertainty level of crps over all the grid points\n",
    "\n",
    "data=crps_score_time_series[:,:,0] \n",
    "data=data.T\n",
    "mean = da.mean(data, axis=0)\n",
    "std = da.std(data, axis=0)\n",
    "confidence_interval = 1.96 * std / da.sqrt(data.shape[0])\n",
    "# Generate datetime index\n",
    "date_range = pd.date_range(start='2020-01-01 00:00:00', end='2022-11-30 18:00:00', periods=4260)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=mean.astype(np.float32)\n",
    "confidence_interval=confidence_interval.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each realization\n",
    "#for i in range(data.shape[0]):\n",
    "#    plt.plot(date_range,data[i], color='gray', alpha=0.1)\n",
    "\n",
    "# Plot the mean time series\n",
    "plt.plot(date_range,mean, color='blue', label='Mean')\n",
    "\n",
    "# Shade the confidence interval\n",
    "plt.fill_between(date_range, mean - confidence_interval, mean + confidence_interval, color='blue', alpha=0.3, label='95% Confidence Interval')\n",
    "\n",
    "plt.xlabel('Time Steps', fontsize=14)\n",
    "plt.ylabel('swvl1', fontsize=14)\n",
    "plt.title('CRPS time seires of swvl1 over all grid cells', fontsize=14)\n",
    "plt.legend(fontsize=12)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlim(pd.Timestamp('2020-01-01 00:00:00'), pd.Timestamp('2022-11-30 18:00:00'))\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
