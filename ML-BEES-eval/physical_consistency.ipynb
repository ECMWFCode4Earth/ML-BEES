{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from eval_utilities import spatial_temporal_metrics as stm\n",
    "from eval_utilities import visualization as vis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(f\"config.yaml\") as stream:\n",
    "    try:\n",
    "        CONFIG = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ref = xr.open_zarr(CONFIG[\"path_ec_euro\"]).sel(time=slice(\"2021-01-01T00\", \"2022-11-30T00\"))\n",
    "ds_mod = xr.open_zarr(CONFIG[\"path_xgb_diag_v2\"]).sel(time=slice(\"2021-01-01T00\", \"2022-11-30T00\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Soil Moisture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field Capacity vs. Average Soil Moisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Climate info:\n",
    "field_cap = ds_ref.clim_data.sel(clim_variable=\"clim_theta_cap\")\n",
    "wilt_point = ds_ref.clim_data.sel(clim_variable=\"clim_theta_pwp\")\n",
    "\n",
    "# Average over time and soil moisture levels:\n",
    "avg_ref = ds_ref.sel(variable=[\"swvl1\",\"swvl2\",\"swvl3\"]).data.mean(dim=(\"time\", \"variable\"))\n",
    "avg_mod = ds_mod.sel(variable=[\"swvl1\",\"swvl2\",\"swvl3\"]).data.mean(dim=(\"time\", \"variable\"))\n",
    "\n",
    "\n",
    "# Assemble data for boxplots:\n",
    "fcaps = sorted(set(field_cap.values))\n",
    "boxes_ref = []\n",
    "boxes_mod = []\n",
    "for fcap in fcaps:\n",
    "    _ = avg_ref.where(ds_ref.clim_data.sel(clim_variable=\"clim_theta_cap\") == fcap).values\n",
    "    _ = _[~np.isnan(_)]\n",
    "    boxes_ref.append(_)\n",
    "\n",
    "    _ = avg_mod.where(ds_ref.clim_data.sel(clim_variable=\"clim_theta_cap\") == fcap).values\n",
    "    _ = _[~np.isnan(_)]\n",
    "    boxes_mod.append(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = plt.boxplot(boxes_ref, positions=np.array(range(len(fcaps)))*2.0-0.4, widths=0.6)\n",
    "bpm = plt.boxplot(boxes_mod, positions=np.array(range(len(fcaps)))*2.0+0.4, widths=0.6)\n",
    "plt.xticks(range(0, len(fcaps) * 2, 2), fcaps)\n",
    "\n",
    "# Distinguish mod and ref:\n",
    "plt.setp(bpr['medians'], color=\"tab:orange\", label=\"ref\")\n",
    "plt.setp(bpm['medians'], color=\"tab:blue\", label=\"mod\")\n",
    "\n",
    "# Get rid of duplicates in the legend:\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "\n",
    "plt.xlabel(\"Field Capacity\")\n",
    "plt.ylabel(\"Average (time and vert) Soil Moisture\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity of Soil Moisture to Soil Properties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first part is modified from \"inference_xgboost.iypnb\". It contains all necessary ingredients for running the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from eval_utilities.EclandPointDataset import EcDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/data/ecland_i6aj_o400_2010_2022_6h_euro.zarr\"\n",
    "model_path = \"/home/ch23/weights_ch23/euro_xgb_train_2019_val_2020_all_variables.json\"\n",
    "spatial_encoding = False\n",
    "temporal_encoding = False\n",
    "\n",
    "# Dataset:\n",
    "ds_inf = EcDataset(start_year = 2020, end_year = 2022, root = data_path, roll_out = 1, \n",
    "                   #clim_features=CONFIG[\"clim_feats\"], dynamic_features=CONFIG[\"dynamic_feats\"],\n",
    "                   #target_prog_features=CONFIG[\"targets_prog\"], target_diag_features=CONFIG[\"targets_diag\"],\n",
    "                   is_add_lat_lon = spatial_encoding, \n",
    "                   is_norm = True, \n",
    "                   point_dropout = 0.0)\n",
    "\n",
    "# XGB Model:\n",
    "model = xgb.XGBRegressor(n_estimators=1000, tree_method=\"hist\", device=\"cuda\")\n",
    "model.load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output should neither be stored nor is it necessary to predict the whole data set. Instead, we want to run the same grid point with different parameters.\n",
    "Here, we are modifying only field capacitiy (for now). To get the whole range, field capacity is varied from $0$ to $0.75$ in steps of $0.05$.\n",
    "The test sites are repeated and stacked to run the inference for all variations at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose test sites:\n",
    "x_coords = [63699, 62986, 62267, 85271] #Bonn, Juelich, Reading, Bologna\n",
    "ii = np.searchsorted(ds_ref[\"x\"], x_coords) #corresponding indices\n",
    "\n",
    "# Get index of field capacity in clim input:\n",
    "i_cap = np.where(np.array(CONFIG[\"clim_feats\"]) == \"clim_theta_cap\")[0][0]\n",
    "\n",
    "# Define new field capacities and normalize:\n",
    "new_caps = (np.arange(0, 0.8, 0.05) - ds_inf.clim_means[i_cap]) / ds_inf.clim_stdevs[i_cap]\n",
    "\n",
    "\n",
    "# Initial state\n",
    "_, x_state, _, _, x_clim, _ = ds_inf[0]\n",
    "x_state, x_clim = x_state.squeeze()[ii], x_clim.squeeze()[ii]\n",
    "preds = [EcDataset.inv_transform(x_state, ds_inf.y_prog_means, ds_inf.y_prog_stdevs)]\n",
    "\n",
    "\n",
    "# Change initial state to contain duplicates of the test sites with the new field capacities:\n",
    "new_states = []\n",
    "new_clims = []\n",
    "for i_site in range(len(x_coords)):\n",
    "    new_states.append(np.vstack([x_state[i_site]] * len(new_caps)))\n",
    "    new_clims.append(np.vstack([x_clim[i_site]] * len(new_caps)))\n",
    "    new_clims[-1][:,i_cap] = new_caps\n",
    "\n",
    "x_state = np.vstack(new_states)\n",
    "x_clim = np.vstack(new_clims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constrained to be applied to each time step:\n",
    "def apply_physical_constraints(x_state):\n",
    "    x_state[:, np.array(ds_inf.target_prog_features)!=\"e\"] = np.clip(x_state[:, np.array(ds_inf.target_prog_features)!=\"e\"], 0, None) # All variables except \"e\" are positive\n",
    "    x_state[:,-1] = np.clip(x_state[:,-1], None, 100) # Snow cover cannot be higher than 100\n",
    "    return x_state\n",
    "\n",
    "# Inference\n",
    "for i in tqdm(range(len(ds_inf)), desc=\"Running ECLand emulator...\"):\n",
    "    x_met, _, _, _, _, _ = ds_inf[i]\n",
    "    x_met = x_met.squeeze()[ii]\n",
    "    \n",
    "    # Duplicate weather conditions to match the structure above:\n",
    "    x_met = np.vstack([np.vstack([x_met[i_site]] * len(new_caps)) for i_site in range(len(x_coords))])\n",
    "    \n",
    "    X = np.concatenate((x_met, x_state, x_clim), axis=1)\n",
    "    y_pred = model.predict(X)\n",
    "    y_state_inc_pred = y_pred[:,:len(ds_inf.target_prog_features)]\n",
    "    y_state_inc_pred = EcDataset.inv_transform(y_state_inc_pred, ds_inf.y_prog_inc_mean, ds_inf.y_prog_inc_std) # Unnormalize so that it can be added to the normalized state vector\n",
    "    x_state += y_state_inc_pred\n",
    "    x_state = apply_physical_constraints(EcDataset.inv_transform(x_state, ds_inf.y_prog_means, ds_inf.y_prog_stdevs)) # Unnormalize updated state vector and apply consistency constraints\n",
    "    preds.append(x_state)\n",
    "    x_state = EcDataset.transform(x_state, ds_inf.y_prog_means, ds_inf.y_prog_stdevs) # Re-normalize state vector for next iteration\n",
    "\n",
    "result = np.stack(preds[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "i_swvl1 = np.where(np.array(ds_inf.target_prog_features) == \"swvl1\")[0][0]\n",
    "\n",
    "for i in range(12):\n",
    "    ax.plot(ds_inf[\"time\"], result[:,i,i_swvl1])\n",
    "\n",
    "ax.set(ylabel=\"swvl1\")\n",
    "plt.tick_params(rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity of Evaporation to Soil Moisture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coords = {\"Bonn\": 63699, \"Juelich\": 62986, \"Reading\": 62267, \"Bologna\": 85271}\n",
    "\n",
    "mod_lhf = ds_mod.sel(variable=\"slhf\").data / 3600.\n",
    "ref_lhf = ds_ref.sel(variable=\"slhf\").data / 3600.\n",
    "R_n = ds_ref.sel(variable=\"met_lwdown\").data + ds_ref.sel(variable=\"met_swdown\").data\n",
    "\n",
    "mod_sm = ds_mod.sel(variable=[\"swvl1\",\"swvl2\"]).data.mean(dim=\"variable\")\n",
    "ref_sm = ds_ref.sel(variable=[\"swvl1\",\"swvl2\"]).data.mean(dim=\"variable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,x in x_coords.items():\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    ax.scatter(mod_sm.sel(x=x), -mod_lhf.sel(x=x) / R_n.sel(x=x), marker=\".\")\n",
    "    ax.scatter(ref_sm.sel(x=x), -ref_lhf.sel(x=x) / R_n.sel(x=x), marker=\".\")\n",
    "\n",
    "    ax.axvline(wilt_point.sel(x=x), color=\"tab:grey\")\n",
    "    ax.text(wilt_point.sel(x=x), 0.99, 'WILT', color='tab:grey', ha='right', va='top', rotation=90, transform=ax.get_xaxis_transform())\n",
    "\n",
    "    ax.set(title=f\"SM Regimes for {name}\", xlabel=\"Average Soil Moisture lvl 1-2\", ylabel=\"Latent Flux / Incoming Radiation\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the water balance equation: delta S=P-E-R -- long-term delta S should be 0 -- yearly?\n",
    "eval_ds = xr.open_zarr(\"/data/ch23/euro_xgb_train_2010_2019_val_2020_2020_diagnostic_v2.zarr\")  # Global dataset\n",
    "# train_ds = xr.open_zarr(\"/data/ecland_i6aj_o400_2010_2022_6h_euro.zarr\")  # Europe subset\n",
    "eval_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "(eval_ds\n",
    " .data\n",
    " .isel(time=2)\n",
    " .sel(variable=\"e\").to_dataset()\n",
    " .plot.scatter(x=\"lon\", y=\"lat\", hue=\"data\", s=10, edgecolors=\"none\",figsize=(12,6))\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = xr.open_zarr(\"/data/ecland_i6aj_o400_2010_2022_6h_euro.zarr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "(train_ds\n",
    " .data\n",
    " .isel(time=102)\n",
    " .sel(variable=\"e\").to_dataset()\n",
    " .plot.scatter(x=\"lon\", y=\"lat\", hue=\"data\", s=10, edgecolors=\"none\",vmin=-0.003,vmax=0,figsize=(12,6))\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly Water Balance Evaluation...Test in 2020\n",
    "# P-ET-R=delta S\n",
    "# what is the unit? \n",
    "# P seems to be much smaller than E?\n",
    "# Discharge is very large\n",
    "\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2020-11-30 12:00:00'\n",
    "\n",
    "train_ds_p = train_ds.data.sel(variable=\"met_rainf\",time=slice(start_date, end_date))\n",
    "train_ds_e= train_ds.data.sel(variable=\"e\",time=slice(start_date, end_date))\n",
    "train_ds_dis= train_ds.data.sel(variable=\"dis\",time=slice(start_date, end_date))\n",
    "\n",
    "eval_ds_e= eval_ds.data.sel(variable=\"e\",time=slice(start_date, end_date))\n",
    "eval_ds_dis= eval_ds.data.sel(variable=\"dis\",time=slice(start_date, end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate yearly sum/mean\n",
    "\n",
    "train_ds_p.sum(dim='time').values*1000\n",
    "train_ds_e.sum(dim='time').values*1000\n",
    "train_ds_dis.mean(dim='time').values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
