{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from eval_utilities import spatial_temporal_metrics as stm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(f\"config.yaml\") as stream:\n",
    "    try:\n",
    "        CONFIG = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/conda/envs/ailand/lib/python3.12/site-packages/xarray/backends/plugins.py:80: RuntimeWarning: Engine 'cfgrib' loading failed:\n",
      "Cannot find the ecCodes library\n",
      "  warnings.warn(f\"Engine {name!r} loading failed:\\n{ex}\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "ds_ref = xr.open_zarr(CONFIG[\"path_ec_euro\"]).sel(time=slice(\"2021-01-01T00\", \"2022-11-30T00\"))\n",
    "cell_areas = ds_ref.clim_data.sel(clim_variable=\"clim_cell_area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snow Cover Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ILAMB validation framework defines scoring functions using the relative errors (c.f. functions bias or rmse in \"spatial_temporal_metrics.py\"). To arrive at one summarizing metric, a spatial average over the region of interest is performed. This might also include a weighting function. The relative error is then passed to the exponential function to map to $[0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(relative_error, alpha=1):\n",
    "    return( np.exp(-alpha * relative_error) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the example of snow cover. Obviously, not all grid points experience the same amount of snow. Consequently, it is useful to weight the spatial average using an appropriate measure. Here, we are using the average snow cover over the time series. See the plots below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"snowc\"\n",
    "\n",
    "fname = \"/home/ch23/data_ch23/evalution_results/xgbosst_train_2010_2019_val_2020_2020_est_50_hist/spatial/bias.zarr\"\n",
    "ds_bias = xr.open_zarr(fname)\n",
    "\n",
    "fname = \"/home/ch23/data_ch23/evalution_results/xgbosst_train_2010_2019_val_2020_2020_est_50_hist/spatial/nor_bias.zarr\"\n",
    "ds_bias_rel = xr.open_zarr(fname)\n",
    "\n",
    "# Plot average snowc:\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set(title=f\"Average snow cover\")\n",
    "\n",
    "im = ax.scatter(ds_bias[\"lon\"], ds_bias[\"lat\"], c=ds_ref.data.sel(variable=var).mean(dim=\"time\"), s=10)\n",
    "fig.colorbar(im)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot snowc bias:\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set(title=f\"Bias {var}\")\n",
    "\n",
    "vmin = np.nanpercentile(ds_bias.sel(variable=var).data, 1, axis=0)\n",
    "vmax = np.nanpercentile(ds_bias.sel(variable=var).data, 99, axis=0)\n",
    "im = ax.scatter(ds_bias[\"lon\"], ds_bias[\"lat\"], c=ds_bias.sel(variable=var).data, s=10, vmin=vmin, vmax=vmax)\n",
    "fig.colorbar(im)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the weighting, we can reduce the impact of areas with little snow. The effect is visible in the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"No weights:\\t{score(stm.spatial_mean(ds_bias_rel, vars=var, cell_areas=cell_areas)).values}\")\n",
    "\n",
    "weights = {\"snowc\": ds_ref.data.sel(variable=var).mean(dim=\"time\")}\n",
    "print(f\"With weights:\\t{score(stm.spatial_mean(ds_bias_rel, vars=var, cell_areas=cell_areas, weights=weights[var])).values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores for bias, RMSE and phase shift are computed using the ILAMB scoring approach. Spatial means (possibly weighted) of relative errors for bias and RMSE are passed through an exponential function. Thus, a score of 1 is a perfect match.\n",
    "\n",
    "ACC and phase shift are treated differently from those variables, because they are bounded. Phase shift is mapped to $[0,1]$ and ACC is already in \"[-1,1]$. Therefore, only a spatial average is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_paths = CONFIG[\"eval_paths\"]\n",
    "\n",
    "metric_fnames = {\"Bias\": \"nor_bias.zarr\",\n",
    "                 \"RMSE\": \"nor_rmse.zarr\",\n",
    "                 \"ACC\": \"acc.zarr\",\n",
    "                 }#\"Phase Shift\": \"phase_shift.zarr\"}\n",
    "\n",
    "variables = CONFIG[\"targets_prog\"] + CONFIG[\"targets_diag\"]\n",
    "\n",
    "weights = {\"swvl1\": ds_ref.clim_data.sel(clim_variable=\"clim_theta_cap\"), #use field capacity to emphasize potentially moist grid points\n",
    "           \"swvl2\": ds_ref.clim_data.sel(clim_variable=\"clim_theta_cap\"),\n",
    "           \"swvl3\": ds_ref.clim_data.sel(clim_variable=\"clim_theta_cap\"),\n",
    "           \"stl1\": None,\n",
    "           \"stl2\": None,\n",
    "           \"stl3\": None,\n",
    "           \"snowc\": ds_ref.data.sel(variable=\"snowc\").mean(dim=\"time\"), #weigh by how much snow there is at all\n",
    "           \"d2m\": None,\n",
    "           \"t2m\": None,\n",
    "           \"skt\": None,\n",
    "           \"sshf\": None,\n",
    "           \"slhf\": None,\n",
    "           \"aco2gpp\": ds_ref.clim_data.sel(clim_variable=[\"clim_veg_covl\", \"clim_veg_covh\"]).sum(dim=\"clim_variable\"), #\"amount\" of plant cover\n",
    "           \"dis\": None,\n",
    "           \"e\": None,\n",
    "           \"sro\": None,\n",
    "           \"ssro\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_table_header(f, metric, vars):\n",
    "    \"\"\"\n",
    "    Script to generate a simple markdown table header and write it to file stream `f`.\n",
    "    \"\"\"\n",
    "    first_line = f\"|{metric}|\" #first line contains the metric and the variable names\n",
    "    second_line = \"|-|\" #second line is just filled with dashes\n",
    "\n",
    "    for var in vars: #automatically match number of variables\n",
    "        first_line += f\"{var}|\"\n",
    "        second_line += \":-:|\"\n",
    "\n",
    "    # Write:\n",
    "    f.write(first_line + \"\\n\")\n",
    "    f.write(second_line + \"\\n\")\n",
    "\n",
    "def smean_filtered(ds_metric, vars, cell_areas, weights):\n",
    "    \"\"\"\n",
    "    Modify the spatial mean in the metrics module to remove infinite values \n",
    "    and cut outliers at the 99th percentile to not skew scores too much.\n",
    "    \"\"\"\n",
    "    relative_error = ds_metric.data.sel(variable=vars).values\n",
    "    relative_error[np.isinf(relative_error)] = np.nan\n",
    "    mask = relative_error < np.nanpercentile(relative_error, 99)\n",
    "\n",
    "    if weights is None:\n",
    "        weights = np.ones(ds_metric.sizes[\"x\"]) #uniform weights\n",
    "\n",
    "    total_weighted_area = (weights[mask] * cell_areas[mask]).sum(dim=\"x\") \n",
    "    spatial_integral = (weights[mask] * relative_error[mask] * cell_areas[mask]).sum(dim=\"x\")\n",
    "\n",
    "    return( spatial_integral/total_weighted_area )\n",
    "\n",
    "def score(relative_error, alpha=1):\n",
    "    return( np.exp(-alpha * relative_error) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scoreboard.md\", \"w\") as f:\n",
    "    # Write title:\n",
    "    f.write(\"# AILand Score Board\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"A score of one corresponds to a perfect relative error across all grid points. \"\\\n",
    "             \"The score asymptotically approaches zero for large relative errors.\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    # Generate a table for every metric seperately:\n",
    "    for metric in metric_fnames.keys():\n",
    "        # Write metric sub titles:\n",
    "        f.write(f\"## {metric}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        gen_table_header(f, metric, variables)\n",
    "\n",
    "        # Add a line for every model:\n",
    "        for model in model_paths.keys():\n",
    "            ds_metric = xr.open_zarr(f\"{model_paths[model]}/spatial/{metric_fnames[metric]}\")\n",
    "            current_line = f\"|{model}|\"\n",
    "\n",
    "            for var in variables:\n",
    "                if var not in ds_metric[\"variable\"]:\n",
    "                    var_score = np.nan\n",
    "                elif metric == \"ACC\":\n",
    "                    var_score = smean_filtered(ds_metric, vars=var, cell_areas=cell_areas, weights=weights[var]).values.item()\n",
    "                elif metric == \"Phase Shift\":\n",
    "                    normalized = 0.5 * (1. + np.cos(2. * np.pi * ds_metric / 365.))\n",
    "                    var_score = smean_filtered(normalized, vars=var, cell_areas=cell_areas, weights=weights[var]).values.item()\n",
    "                else:\n",
    "                    var_score = score(smean_filtered(ds_metric, vars=var, cell_areas=cell_areas, weights=weights[var])).values.item()\n",
    "\n",
    "                current_line += f\"{var_score:.2f}|\"\n",
    "            f.write(current_line + \"\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
