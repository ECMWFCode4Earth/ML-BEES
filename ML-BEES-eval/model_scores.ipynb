{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "from eval_utilities import spatial_temporal_metrics as stm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open(f\"config.yaml\") as stream:\n",
    "    try:\n",
    "        CONFIG = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_ref = xr.open_zarr(CONFIG[\"path_ec_euro\"]).sel(time=slice(\"2021-01-01T00\", \"2022-11-30T00\"))\n",
    "cell_areas = ds_ref.clim_data.sel(clim_variable=\"clim_cell_area\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snow Cover Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ILAMB validation framework defines scoring functions using the relative errors (c.f. functions bias or rmse in \"spatial_temporal_metrics.py\"). To arrive at one summarizing metric, a spatial average over the region of interest is performed. This might also include a weighting function. The relative error is then passed to the exponential function to map to $[0,1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(relative_error, alpha=1):\n",
    "    return( np.exp(-alpha * relative_error) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the example of snow cover. Obviously, not all grid points experience the same amount of snow. Consequently, it is useful to weight the spatial average using an appropriate measure. Here, we are using the average snow cover over the time series. See the plots below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = \"snowc\"\n",
    "\n",
    "fname = \"/home/ch23/data_ch23/evalution_results/xgbosst_train_2010_2019_val_2020_2020_est_50_hist/spatial/bias.zarr\"\n",
    "ds_bias = xr.open_zarr(fname)\n",
    "\n",
    "fname = \"/home/ch23/data_ch23/evalution_results/xgbosst_train_2010_2019_val_2020_2020_est_50_hist/spatial/nor_bias.zarr\"\n",
    "ds_bias_rel = xr.open_zarr(fname)\n",
    "\n",
    "# Plot average snowc:\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set(title=f\"Average snow cover\")\n",
    "\n",
    "im = ax.scatter(ds_bias[\"lon\"], ds_bias[\"lat\"], c=ds_ref.data.sel(variable=var).mean(dim=\"time\"), s=10)\n",
    "fig.colorbar(im)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Plot snowc bias:\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.set(title=f\"Bias {var}\")\n",
    "\n",
    "vmin = np.nanpercentile(ds_bias.sel(variable=var).data, 1, axis=0)\n",
    "vmax = np.nanpercentile(ds_bias.sel(variable=var).data, 99, axis=0)\n",
    "im = ax.scatter(ds_bias[\"lon\"], ds_bias[\"lat\"], c=ds_bias.sel(variable=var).data, s=10, vmin=vmin, vmax=vmax)\n",
    "fig.colorbar(im)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the weighting, we can reduce the impact of areas with little snow. The effect is visible in the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"No weights:\\t{score(stm.spatial_mean(ds_bias_rel, vars=var, cell_areas=cell_areas)).values}\")\n",
    "\n",
    "weights = {\"snowc\": ds_ref.data.sel(variable=var).mean(dim=\"time\")}\n",
    "print(f\"With weights:\\t{score(stm.spatial_mean(ds_bias_rel, vars=var, cell_areas=cell_areas, weights=weights[var])).values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might consider moving this to config.yaml later?\n",
    "model_paths = {\"xgb_v1\": \"/home/ch23/data_ch23/evalution_results/xgbosst_train_2010_2019_val_2020_2020_est_50_hist/\"}\n",
    "\n",
    "metric_fnames = {\"Bias\": \"nor_bias.zarr\",\n",
    "                 \"RMSE\": \"nor_rmse.zarr\",\n",
    "                 \"ACC\": \"acc.zarr\",\n",
    "                 \"Phase Shift\": \"phase_shift.zarr\"}\n",
    "\n",
    "variables = [\"swvl1\", \"swvl2\", \"swvl3\", \"stl1\", \"stl2\", \"stl3\", \"snowc\"]\n",
    "\n",
    "weights = {\"swvl1\": ds_ref.clim_data.sel(clim_variable=\"clim_theta_cap\"), #use field capacity to emphasize potentially moist grid points\n",
    "           \"swvl2\": ds_ref.clim_data.sel(clim_variable=\"clim_theta_cap\"),\n",
    "           \"swvl3\": ds_ref.clim_data.sel(clim_variable=\"clim_theta_cap\"),\n",
    "           \"stl1\": None,\n",
    "           \"stl2\": None,\n",
    "           \"stl3\": None,\n",
    "           \"snowc\": ds_ref.data.sel(variable=var).mean(dim=\"time\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_table_header(f, metric, vars):\n",
    "    \"\"\"\n",
    "    Script to generate a simple markdown table header and write it to file stream `f`.\n",
    "    \"\"\"\n",
    "    first_line = f\"|{metric}|\" #first line contains the metric and the variable names\n",
    "    second_line = \"|-|\" #second line is just filled with dashes\n",
    "\n",
    "    for var in vars: #automatically match number of variables\n",
    "        first_line += f\"{var}|\"\n",
    "        second_line += \":-:|\"\n",
    "\n",
    "    # Write:\n",
    "    f.write(first_line + \"\\n\")\n",
    "    f.write(second_line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"scoreboard.md\", \"w\") as f:\n",
    "    # Write title:\n",
    "    f.write(\"# AILand Score Board\\n\")\n",
    "    f.write(\"\\n\")\n",
    "    \n",
    "    # Generate a table for every metric seperately:\n",
    "    for metric in metric_fnames.keys():\n",
    "        # Write metric sub titles:\n",
    "        f.write(f\"## {metric}\\n\")\n",
    "        f.write(\"\\n\")\n",
    "        gen_table_header(f, metric, variables)\n",
    "\n",
    "        # Add a line for every model:\n",
    "        for model in model_paths.keys():\n",
    "            ds_metric = xr.open_zarr(f\"{model_paths[model]}/spatial/{metric_fnames[metric]}\")\n",
    "            current_line = f\"|{model}|\"\n",
    "\n",
    "            for var in variables:\n",
    "                var_score = score(stm.spatial_mean(ds_metric, vars=var, cell_areas=cell_areas, weights=weights[var])).values.item()\n",
    "                current_line += f\"{var_score:.2f}|\"\n",
    "            f.write(current_line + \"\\n\")\n",
    "        f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
