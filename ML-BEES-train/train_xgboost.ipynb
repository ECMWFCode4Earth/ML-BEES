{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training XGBoost to Emulate ec-land\n",
    "\n",
    "In this notebook we take some example Zarr data (similar to that created by this projects other functionality) and train an ML emulator of the ec-land land surface model. Here we are training on features of climatological, meteorological and previous model state values to predict the 6-hourly model state update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "source": [
    "import random\n",
    "import xarray as xr\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import r2_score, mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# def r2_score_multi(y_pred: np.ndarray, y_true: np.ndarray) -> float:\n",
    "#     \"\"\"Calculated the r-squared score between 2 arrays of values\n",
    "\n",
    "#     :param y_pred: predicted array\n",
    "#     :param y_true: \"truth\" array\n",
    "#     :return: r-squared metric\n",
    "#     \"\"\"\n",
    "#     return r2_score(y_pred.flatten(), y_true.flatten())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "source": [
    "# Open up the Zarr data\n",
    "ds_train = xr.open_zarr(\"/data/ecland_i6aj_o400_2010_2022_6h_euro.zarr\").sel(time=slice(\"2010\", \"2019\"))\n",
    "ds_val = xr.open_zarr(\"/data/ecland_i6aj_o400_2010_2022_6h_euro.zarr\").sel(time=slice(\"2020\", \"2020\"))\n",
    "# Inspect the concatenated dataset and see available model variables"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we select the \"features\" and \"targets\" that we want to use to use in the construction of our ML model. The we select this subset of variables from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "clim_feat_lst = ['clim_clake',\n",
    "            'clim_ctype',\n",
    "            'clim_landsea',\n",
    "            'clim_cu',\n",
    "            'clim_cvh',\n",
    "            'clim_cvl',\n",
    "            'clim_geopot',\n",
    "            'clim_sdfor',\n",
    "            'clim_sdor',\n",
    "            # 'clim_sotype',\n",
    "            # 'clim_tvh',\n",
    "            # 'clim_tvl',\n",
    "            'clim_theta_cap',\n",
    "            'clim_theta_pwp',\n",
    "            'clim_veg_covh',\n",
    "            'clim_veg_covl',\n",
    "            'clim_veg_z0mh',\n",
    "            'clim_veg_z0ml',\n",
    "            'clim_veg_rsminh',\n",
    "            'clim_veg_rsminl']\n",
    "\n",
    "\n",
    "feat_lst = ['lai_hv', \n",
    "            'lai_lv', \n",
    "            'met_ctpf',\n",
    "            'met_lwdown',\n",
    "            'met_psurf',\n",
    "            'met_qair',\n",
    "            'met_rainf',\n",
    "            'met_swdown',\n",
    "            'met_snowf',\n",
    "            'met_tair',\n",
    "            'met_wind_e',\n",
    "            'met_wind_n',\n",
    "            'swvl1',\n",
    "            'swvl2',\n",
    "            'swvl3',\n",
    "            'stl1',\n",
    "            'stl2',\n",
    "            'stl3',\n",
    "            'snowc',\n",
    "           ]\n",
    "\n",
    "targ_lst = ['swvl1',\n",
    "            'swvl2',\n",
    "            'swvl3',\n",
    "            'stl1',\n",
    "            'stl2',\n",
    "            'stl3',\n",
    "            'snowc',\n",
    "           ]\n",
    "\n",
    "def prepare_feats_and_targets(ds):\n",
    "\n",
    "    # Shift the times of the features/targets so that from the previous state we are predicting the next state\n",
    "    clim_feats_ds = (ds.sel(clim_variable=clim_feat_lst).clim_data\n",
    "                    .expand_dims(time=ds.time)\n",
    "                    .isel(time=slice(0,-1))\n",
    "                    .stack(z=(\"x\", \"time\",))\n",
    "                    .transpose()\n",
    "                    .rename({\"clim_variable\": \"variable\"})\n",
    "    )\n",
    "    feats_ds = ds.sel(variable=feat_lst).isel(time=slice(0,-1)).data.stack(z=(\"x\", \"time\",)).transpose()\n",
    "    target_ds = ds.sel(variable=targ_lst).data\n",
    "\n",
    "    # Select the desired variables, convert to an array, stack the 'time' and 'space' dimensions. \n",
    "    # For the targets we minus the previous value of the model state so that we are predicting \n",
    "    # the 6-hourly model update increments instead of the next absolutle model value.\n",
    "    feats_ds = xr.concat((clim_feats_ds, feats_ds), dim=\"variable\").chunk({\"variable\": -1})\n",
    "    target_ds = target_ds.isel(time=slice(1,None)).stack(z=(\"x\", \"time\",)).transpose() - target_ds.isel(time=slice(0,-1)).stack(z=(\"x\", \"time\",)).values.T\n",
    "\n",
    "    return feats_ds, target_ds"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "source": [
    "train_feats, train_targets = prepare_feats_and_targets(ds_train)\n",
    "val_feats, val_targets = prepare_feats_and_targets(ds_val)\n",
    "\n",
    "n_train = train_feats.shape[0]\n",
    "n_val = val_feats.shape[0]\n",
    "\n",
    "print(n_train, n_val)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training with XGBoost\n",
    "\n",
    "Now we have our \"features\" and \"targets\" we can train xgboost to predict our model increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "source": [
    "def mse(y_pred: np.ndarray, y_true: np.ndarray) -> float:\n",
    "    return mean_squared_error(y_pred.flatten(), y_true.flatten())\n",
    "\n",
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=50,\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cuda\",\n",
    "    objevtive=mse,\n",
    "    # multi_strategy=\"multi_output_tree\",\n",
    "    # learning_rate=0.3,\n",
    "    # eval_metric=mse,\n",
    "    # subsample=0.01,\n",
    "    # sampling_method=\"gradient_based\"\n",
    ")\n",
    "# fname = \"./test.json\"\n",
    "\n",
    "# X_train = train_feats.values\n",
    "# y_train = train_targets.values\n",
    "# X_val = val_feats.values\n",
    "# y_val = val_targets.values\n",
    "\n",
    "# print(\"Fitting XGB model...\")\n",
    "\n",
    "# # At once\n",
    "# model.fit(X_train, y_train, eval_set=[(X_val, y_val)])\n",
    "# model.save_model(fname)\n",
    "# y_val_pred = model.predict(X_val)\n",
    "# val_mse = mse(y_val_pred, y_val)\n",
    "# print(f\"Validation MSE = {val_mse}\")\n",
    "\n",
    "# # Incremental\n",
    "# batch_size = 20000\n",
    "# i = 0\n",
    "# val_mse_curr = float('inf')\n",
    "# while True:\n",
    "#     idxs = np.random.choice(n_train, batch_size, replace=False)\n",
    "#     X_batch = X_train[idxs]\n",
    "#     y_batch = y_train[idxs]\n",
    "#     model.fit(X_batch, y_batch, eval_set=[(X_batch, y_batch)], xgb_model=fname if i>0 else None, verbose=False)\n",
    "#     model.save_model(fname)\n",
    "#     y_val_pred = model.predict(X_val)\n",
    "#     if i%5 == 0:\n",
    "#         val_mse = mse(y_val_pred, y_val)\n",
    "#         print(f\"Epoch {i}: Validation MSE = {val_mse}\")\n",
    "#         if val_mse < val_mse_curr:\n",
    "#             val_mse_curr = val_mse\n",
    "#             i+=1\n",
    "#         else:\n",
    "#             break\n",
    "\n",
    "# print(\"Finished training\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailand",
   "language": "python",
   "name": "ailand"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
