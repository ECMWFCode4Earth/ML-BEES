{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training XGBoost to Emulate ec-land\n",
    "\n",
    "In this notebook we take some example Zarr data (similar to that created by this projects other functionality) and train an ML emulator of the ec-land land surface model. Here we are training on features of climatological, meteorological and previous model state values to predict the 6-hourly model state update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import xgboost as xgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "from dataset.EclandPointDataset import EcDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/data/ecland_i6aj_o400_2010_2022_6h_euro.zarr\"\n",
    "model_path = \"./test.json\"\n",
    "spatial_encoding = False\n",
    "temporal_encoding = False\n",
    "\n",
    "with open('config.yaml') as stream:\n",
    "    try:\n",
    "        CONFIG = yaml.safe_load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data(ds):\n",
    "\n",
    "    x_met, x_state, y_state_inc, y_diag, x_clim, x_time = [], [], [], [], [], []\n",
    "    for i in tqdm(range(len(ds)), desc=\"Loading dataset...\"):\n",
    "        x_met_i, x_state_i, y_state_inc_i, y_diag_i, x_clim_i, x_time_i = ds[i]\n",
    "        x_met.append(torch.tensor(x_met_i).squeeze())\n",
    "        x_state.append(torch.tensor(x_state_i).squeeze())\n",
    "        y_state_inc.append(torch.tensor(y_state_inc_i).squeeze())\n",
    "        y_diag.append(torch.tensor(y_diag_i).squeeze())\n",
    "        x_clim.append(torch.tensor(x_clim_i).squeeze())\n",
    "        x_time.append(torch.tensor(x_time_i).repeat(x_met_i.shape[1], 1))\n",
    "\n",
    "    return torch.cat(x_met), torch.cat(x_state), torch.cat(y_state_inc), torch.cat(y_diag), torch.cat(x_clim), torch.cat(x_time)\n",
    "\n",
    "ds_train = EcDataset(\n",
    "    start_year = 2010, \n",
    "    end_year = 2019, \n",
    "    root = data_path, \n",
    "    roll_out = 1, \n",
    "    clim_features=CONFIG[\"clim_feats\"],\n",
    "    dynamic_features=CONFIG[\"dynamic_feats\"],\n",
    "    target_prog_features=CONFIG[\"targets_prog\"],\n",
    "    target_diag_features=CONFIG[\"targets_diag\"],\n",
    "    is_add_lat_lon = spatial_encoding, \n",
    "    is_norm = True, \n",
    "    dropout = 0.0\n",
    ")\n",
    "x_met, x_state, y_state_inc, y_diag, x_clim, x_time = load_all_data(ds_train)\n",
    "X_train = torch.cat((x_met, x_state, x_time), dim=1) if temporal_encoding else torch.cat((x_met, x_state), dim=1)\n",
    "y_train = torch.cat((y_state_inc, y_diag), dim=1)\n",
    "\n",
    "ds_val = EcDataset(\n",
    "    start_year = 2020, \n",
    "    end_year = 2020, \n",
    "    root = data_path, \n",
    "    roll_out = 1, \n",
    "    clim_features=CONFIG[\"clim_feats\"],\n",
    "    dynamic_features=CONFIG[\"dynamic_feats\"],\n",
    "    target_prog_features=CONFIG[\"targets_prog\"],\n",
    "    target_diag_features=CONFIG[\"targets_diag\"],\n",
    "    is_add_lat_lon = spatial_encoding, \n",
    "    is_norm = True, \n",
    "    dropout = 0.0\n",
    ")\n",
    "x_met, x_state, y_state_inc, y_diag, x_clim, x_time = load_all_data(ds_val)\n",
    "X_val = torch.cat((x_met, x_state, x_time), dim=1) if temporal_encoding else torch.cat((x_met, x_state), dim=1)\n",
    "y_val = torch.cat((y_state_inc, y_diag), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training with XGBoost\n",
    "\n",
    "Now we have our \"features\" and \"targets\" we can train xgboost to predict our model increments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.5,\n",
    "    tree_method=\"hist\",\n",
    "    device=\"cuda\",\n",
    "    # device=\"cpu\",\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "print(\"Fitting XGB model...\")\n",
    "\n",
    "# At once\n",
    "model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_val, y_val)])\n",
    "model.save_model(model_path)\n",
    "\n",
    "results = model.evals_result()\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(results[\"validation_0\"][\"rmse\"], label=\"Training loss\")\n",
    "plt.plot(results[\"validation_1\"][\"rmse\"], label=\"Validation loss\")\n",
    "plt.xlabel(\"Number of trees\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# # Incremental (doesnt work!)\n",
    "# batch_size = 20000\n",
    "# i = 0\n",
    "# val_mse_curr = float('inf')\n",
    "# while True:\n",
    "#     idxs = np.random.choice(n_train, batch_size, replace=False)\n",
    "#     X_batch = X_train[idxs]\n",
    "#     y_batch = y_train[idxs]\n",
    "#     model.fit(X_batch, y_batch, eval_set=[(X_batch, y_batch)], xgb_model=fname if i>0 else None, verbose=False)\n",
    "#     model.save_model(fname)\n",
    "#     y_val_pred = model.predict(X_val)\n",
    "#     if i%5 == 0:\n",
    "#         val_mse = mse(y_val_pred, y_val)\n",
    "#         print(f\"Epoch {i}: Validation MSE = {val_mse}\")\n",
    "#         if val_mse < val_mse_curr:\n",
    "#             val_mse_curr = val_mse\n",
    "#             i+=1\n",
    "#         else:\n",
    "#             break\n",
    "\n",
    "print(\"Finished training\")\n",
    "\n",
    "del X_train, y_train, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_pred: np.ndarray, y_true: np.ndarray) -> float:\n",
    "    return root_mean_squared_error(y_pred.flatten(), y_true.flatten())\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_mse = rmse(y_val_pred, y_val)\n",
    "print(f\"Validation RMSE = {val_mse}\")\n",
    "\n",
    "ds_test = EcDataset(\n",
    "    start_year = 2021, \n",
    "    end_year = 2022, \n",
    "    root = data_path, \n",
    "    roll_out = 1, \n",
    "    clim_features=CONFIG[\"clim_feats\"],\n",
    "    dynamic_features=CONFIG[\"dynamic_feats\"],\n",
    "    target_prog_features=CONFIG[\"targets_prog\"],\n",
    "    target_diag_features=CONFIG[\"targets_diag\"],\n",
    "    is_add_lat_lon = spatial_encoding, \n",
    "    is_norm = True, \n",
    "    dropout = 0.0\n",
    ")\n",
    "x_met, x_state, y_state_inc, y_diag, x_clim, x_time = load_all_data(ds_test)\n",
    "X_test = torch.cat((x_met, x_state, x_time), dim=1) if temporal_encoding else torch.cat((x_met, x_state), dim=1)\n",
    "y_test = torch.cat((y_state_inc, y_diag), dim=1)\n",
    "\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_mse = rmse(y_test_pred, y_test)\n",
    "print(f\"Test RMSE = {test_mse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
